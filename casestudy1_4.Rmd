---
title: "Case 1 Take 4"
author: "Ian Hua, InHee Ho, Sonia Xu"
date: "September 25, 2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r echo = F}
library(dplyr)
library(lme4)
library(ggplot2)
library(magrittr)
library(knitr)
```

```{r include = F}
#Read in the data

dat <- read.table("case1.txt", header = T, stringsAsFactors = F, na.strings = ".", colClasses=c("character","character","numeric","numeric","numeric","numeric","numeric","numeric"))
dat <-  dat %>% filter(complete.cases(blot)) 
```
#Introduction
The following data is from an international validation study (19 labs, 6 nations) of the rat uterotrophic bioassay. The purpose of the assay was to screen chemicals for estrogenic effects--agonist (EE) or antagonist (ZM). One clear challenge from the assay was the consistency among variables and protocols throughout all data in the study. The motivation of this study is to fit the best model against the data to identify potential differences between labs, and to assess the consistency and effectiveness of the two chemicals. An original linear mixed effects model with general transofrmations was fit to the data, however, further exploration showed that a linear mixed effects model with kernel estimates and clustering for certain features provided better results.

#Methodology
Our approach to answer our problem followed these 4 steps: 
1. Data-cleaning

2. Exploratory Data Analysis 

3. Fitting the data to a Linear Mixed-Effect Model 

4. Interpreting the data, model, and results

#Dataset
The final dataset contains 2677 observations and 6 features: lab, protocol, dose 1, dose 2, body weight, and blotted uterus weight.
Three key pieces of data were removed: 4 observations due to missing data, the feature, group, due to multicollinearity, and the feature, wet, due to its variability in capturing the uterus weight. Below is a preview of the final dataset:
```{r echo = F}
kable(head(dat))
```

##Final Model: Linear Mixed Effect Model

#Transitioning from the Linear Mixed Effects Model
In our previous report, we attempted to handle the non-linearity of dose 1 and dose 2 by taking their logarithms and modeling as polynomials with a degree of 2. Overall, our previous final model fitted the data well according to the qq-plot and residual vs. fitted graph. However, using second-degree polynomials of the logarithmized values of dose 1 and dose 2 did not fully capture the uneven distribution of dose 1 and dose 2 against the response, blotted uterus weight. We can better fit the model using kernel regression and clustering. We present below our updated final model that applies kernel estimations to dose 1 and dose 2 and transforms body weight into a categorical variable via k-means clustering, and how the model better predicts our response.

#Exploratory Data Analysis
We continued from our previous report with our choices of explanatory variables. We detected significant heteroscedasticity in our response variable (blotted uterus weight) between labs, and took their logarithms for more consistent variance. Furthermore, protocols can have different effects on the response depending on the labs. We capture such difference by fitting random effects proto|lab. Finally, to capture the effects of doses of chemical 1 and 2 across all labs as well as their variation between labs, we added dose 1 and dose 2 as both fixed and random effects. However, we used different methods to better capture the distributions of dose 1, dose 2, and body weight.


##Capturing the Non-Linearity of Dose 1 and Dose 2
In order to capture the non-linearity of the distribution of dose 1 and dose 2, we decided to use kernel regression instead of modeling with second-degree polynomials of logarithmized values. We use 4 knots for dose 1 and 3 knots for dose 2.

```{r include = F}
#creates a kernel distribution for each covariate
#be careful of random samples--Big X can't have NAs
kern_distribution <- function(x,knots = 4) {
  ### s: #controls how wide the kernels are, s should be half the distance between two knots 
  ### tau: decides where the breaks are based on the number of knots
  ###knots: number of splits/peaks in the data
  ##x and y are the data
  
  tau <- seq(min(x), max(x), length.out = knots)
  s <- diff(tau)[1]/2
  X <- matrix(0, nrow=length(x),ncol=knots)
  for(i in 1:knots) {
    X[,i] <- x * dnorm(x, tau[i], s)
  }
  return(X)
}

#smoothing out the graph by predicting values for the fitted data
#same function as the kern distribution, but this time it is smoother
smooth_graph <- function(x,knots = 4) {
  tau <- seq(min(x), max(x), length.out = knots)
  s <- diff(tau)[1]/2
  x.predict <- seq(min(x), max(x), length.out=length(x))
  X.predict <- matrix(0, nrow=length(x.predict),ncol = knots)
  for(i in 1:knots) {
    X.predict[,i] <- x.predict * dnorm(x.predict, tau[i], s)
  }
  return(X.predict)
}
RMSE <- function(x,y) {return(sqrt(mean((y-x)^2)))} 
```

```{r echo = F, warning= F}

#attach(dat) ##attaches the data so we can just run through with the variable names

m2 <- lmer(log(blot + 1) ~ (1 + proto + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3)|lab) + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3) , data = dat)  #X + Z + R + S + random effect
#summary(m2)
```

```{r echo = F}
plot(dat$dose1,log(dat$blot + 1), col = "red", main = "Fitted Kernels for Dose 1", ylab = "log(blot + 1)", xlab = "dose 1") #plots the true data
lines(sort(dat$dose1), fitted(m2)[order(dat$dose1)]) #shows how well the model fits the true data
#abline(v = tau)

plot(dat$dose2, log(dat$blot + 1), col = "red", main = "Fitted Kernels for Dose 2", ylab = "log(blot + 1)", xlab = "dose 1")
lines(sort(dat$dose2), fitted(m2)[order(dat$dose2)])
#abline(v = tau)

```
##Transforming Body into a Categorical Variable
```{r, echo=F}
ggplot(data = dat, aes(x=body, y=blot))+geom_point(alpha=0.5) + ggtitle("Body vs. Blotted Uterus Weight")
```

Looking at the scatterplot above between body and blotted uterus weight, we observe two distinct groups of body weight. These groups are non-linear, so it would be best to distinguish them in an unsupervised fashion. K-means clustering with 3 groups resulted in the best segmentation of the data, and these groups (1,2,3) replaced the continuous variable of body weight for the final model. Below is a plot of the 3 different clusters.
```{r echo = F}
library(cluster)
set.seed(20)
bodyCluster <- kmeans(dat[, c(6,8)], 3, nstart = 20)

bodyCluster$cluster <- as.factor(bodyCluster$cluster)
ggplot(dat, aes(body, blot, color = bodyCluster$cluster)) + geom_point() +
    labs(color = "cluster") + ggtitle("Body vs. Blotted Uterus Weight with Clusters") 

#Splits the body weight into 3 bins...
##add it back to the data & replace body with these 3 groups

dat$bodyClust <- bodyCluster$cluster
```

```{r include = F}
#smooth version
m3 <- lmer(log(blot + 1) ~ (1 + proto|lab) + smooth_graph(dose1, knots = 3) + smooth_graph(dose2, knots = 3) + smooth_graph(body, knots = 3), data = dat) #X + Z + R + S + random effect
summary(m3)

```

#The Updated Final Model
Thus, our updated final model still has the log of blotted uterus weights as the response variable; protocol, dose 1, and dose 2 as random effects between labs; and dose 1, dose 2, and body weight as fixed effects across all population. But dose 1, dose 2, and body weight now reflect the transformations as noted above.
```{r warning = F}
m4 <- lmer(log(blot+1) ~ (1 + proto + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3)|lab) + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3) + bodyClust, data = dat) 
#X + Z + R + S + random effect
#summary(m4)
```
#Checking Assumptions
```{r echo = F}
plot(m4, main = 'Residuals vs. Fitted', xlab = "Fitted", ylab = "Residuals")
```
Looking at the Residuals vs. Fitted plot, the points exhibit homoscedascity, and overall, the points are randomly and evenly distributed above and below the horizontal axis. This implies that the data should be modeled linearly. 

```{r echo = F}
qqnorm(resid(m4))
```
Checking the normality assumption via the QQ-plot, the points overall follow a straight diagonal trend, which reaffirms that the points are normally distributed.

#Final Model Goodness of Fit
```{r cache = T, echo = F, warning = F}
R5 <- NULL
SD <- NULL
for(i in 1: 100) {
  samp <- sample(dim(dat)[1], dim(dat)[1]/10)
  test <- dat[samp,]
  train <- dat[-samp,]
  ufinmod <- lmer(log(blot + 1) ~ (1 + proto + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3)|lab) + kern_distribution(dose1, knots = 4) + kern_distribution(dose2, knots = 3) + bodyClust, data = dat) 
  p_finmod <- predict(ufinmod, test)
  SD <- rbind(SD, sd(log(test$blot + 1)))
  R5 <- rbind(R5, RMSE(p_finmod, log(test$blot+1)))
}
```

By fitting dose 1 and dose 2 via kernel regression and clustering body into 3 segments, this updated final model produced better predictive results for the train vs. test data. The previous final model had a root mean squared error (RMSE) of 0.2339 after 100 iterations. This final model had a root mean squared error of `r round(mean(R5),3)` after 100 iterations, so it is a slight improvement from our previous final model.

#Discussion of Updated Final Model
This updated final model produced similar results to the previous final model. 

#Differences in the Effects of Dose 1, Dose 2, and Protocol Between Labs
High variance suggests that these labs are not comparable because it suggests that the blotted uterus weight has no distinct response across all labs after adding dose 1, dose 2, or utilizing a certain protocol. Protocol A is used as a baseline for for the random effects. Looking at the variation of the random effects of dose 1, dose 2, and protocol on lab, there exists variation in blotted uterus weight for each of these features between the different labs as denoted by the variance. 

In particular, protocols C & D have a higher variance compared to protocol A. Protocol B has a slightly higher variance compared to protocol A. Thus, protocols C & D may be comparable, but not protocols A & D. Intuitively, this makes sense because the Protcols A and B have lower body weights than Protcols C and D, as illustrated below:
```{r echo = F}
ggplot(dat, aes(body, blot, col = proto)) + geom_point()
```

There exists extremely high variation for dose 1, so the effect of dose 1 highly varies between labs. Although not as high, there also exists variation for dose 2, so the effect of dose 2 also varies between labs. 

#Differences in Body Weight Between Labs
After clustering the body weight of each rat into three categories, with the body weight of group 1 (mean: 349.1) > group 3(mean: 60.4) > group 2(mean: 122.48). Using group 1 as a baseline, if the blotted uterus weight of a rat that was in group 2 increased by one unit, then we would expect a `r round(exp(-1.19)-1,3)` unit decrease in the blotted uterus weight of a rat that was in group 1. If the blotted uterus weight of a rat that was in group 3 increased by one unit, then we would expect a `r round(exp(-006098)-1,3)` unit decrease in the blotted uterus weight of a rat that was in group 1.

Since all labs do not have rats with similar body weights (Lab A's mean body weight: vs Lab X's mean body weight:), these differences in body weight would affect the response, blotted uterus weight, and make the labs again, incomparable.

#Recommendations
Again, differences in protocols seem to matter more than differences in labs. The random and fixed effects of dose 1 and dose 2 on blotted uterus weight vary between labs significantly. Body weight also has a slight effect on blotted uterus weight--the larger the body weight, the heavier the blotted uterus weight. Due to the variability between labs, perhaps not all labs should be compared and rather groupings of similar labs should be investigated as there are many similar labs with negligible differences. 


To avoid this problem altogether, we recommend that this assay would be best conducted in one lab, one standard body weight, and one protocol to ensure consistency in the results. 

#Appendix
```{r warning = F, echo = F}
summary(m4)
```

#Contributions
Sonia Xu: Wrote Case 1, Take 4 (Updated Model, Discussion, etc.)
InHee Ho: Wrote Exploratory Data Analysis, Edited Case 1, Take 4
Ian Hua: Edited Case 1, Take 4 