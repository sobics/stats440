---
title: "Case 1 Take 4"
author: "Ian Hua, InHee Ho, Sonia Xu"
date: "September 25, 2017"
output: html_document
---

##An Attempt at a Non-linear Model

#Read in the data
```{r}
library(dplyr)
dat <- read.table("case1.txt", header = T, stringsAsFactors = F, na.strings = ".", colClasses=c("character","character","numeric","numeric","numeric","numeric","numeric","numeric"))
dat <-  dat %>% filter(complete.cases(blot)) 
```

```{r}
#creates a kernel distribution for each covariate
#be careful of random samples--Big X can't have NAs
kern_distribution <- function(x,y, knots = 4, s = 2) {
  ### s: #controls how wide the kernels are, s should be half the distance between two knots 
  ### tau: decides where the breaks are based on the number of knots
  ###knots: number of splits/peaks in the data
  ##x and y are the data
  
  tau <- seq(min(x), max(x), length.out = knots)
  X <- matrix(0, nrow=length(x),ncol=knots)
  for(i in 1:knots) {
    X[,i] <- x * dnorm(x, tau[i], s)
  }
  return(X)
}
```
#Kernel Distributions
```{r}

attach(dat) ##attaches the data so we can just run through with the variable names

m2 <- lme4(blot ~ kern_distribution(dose1, blot) + kern_distribution(dose2, blot) + kern_distribution(body, blot), data = dat) #X + Z + R + S + random effect
summary(m2)

plot(x$dose1,y$blot)
lines(sort(x$dose1), m2$fitted.values[order(x$dose1)])
abline(v = tau)

#smoothing out the graph
x.predict <- seq(min(x), max(x), length.out=500) #splits data into event little groups
X.predict <- matrix(0, nrow=500,ncol = knots)
for(i in 1:knots) {
  X.predict[,i] <- x.predict * dnorm(x.predict, tau[i], s)
}
y.predict <- cbind(1, X.predict) %*% coef(m2) + cbind #predict function is easier // but cbind(X.predicts)
plot(x,y)

lines(x.predict, y.predict)

```