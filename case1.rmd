---
title: "Case Study Pt. 2"
author: "Ian Hua, InHee Ho, Sonia Xu"
date: "September 9, 2017"
output: html_document
---

#Case Study 1: Write Up 2
```{r include = F}
library(dplyr)
library(lme4)
library(ggplot2)
#read in the data
###plot multiple ggplots in one place  obtained from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

####

RMSE <- function(x,y) {return(sqrt(mean((y-x)^2)))} 
dat <- read.table("case1.txt", header = T, stringsAsFactors = F, na.strings = ".", colClasses=c("character","character","numeric","numeric","numeric","numeric","numeric","numeric"))
dat <-  dat %>% filter(complete.cases(blot)) %>% mutate(wblot = blot/body, wwet = wet/body)
```
To continue our exploration of modelling the data, we decided to split the cleaned dataset from our first write-up into test and training data. We will fit the model on the training data to see how well it fits our test data. Our test data is 1/10 of the full dataset. Another goodness-of-fit measurement we will use is Root Mean Squared Error (RMSE), which measures the difference between the predicted response from a model and the true response the dataset. The lower the RMSE, the better the model fits the data. We sample/fit the test and training data for 100 iterations for each model in an effort to normalize the performance of the models. By understanding how well the models predict the blotted uterus weight, we can see if there is improvement from utilizing more complex models with fixed and random effects in comparison to the simple linear model.

```{r include = F}
set.seed(3)
samp <- sample(dim(dat)[1], dim(dat)[1]/10)
test <- dat[samp,]
train <- dat[-samp,]
```
We believe that the best model predicts the most similar distribution of the test dataset compared to the true test dataset.
Thus, the best models should be the most similar to this quantile:
```{r}
quantile(test$wblot)
```

#Simple Linear Model
```{r}
lm1 <- lm(wblot ~ 1+ poly(dose1,2) + poly(dose2,2), data = train)
par(mfrow=c(2,2))
plot(lm1)
```

```{r include = F, warnings = F, cache = T}
R1 <- NULL
for(i in 1: 100) {
  samp <- sample(dim(dat)[1], dim(dat)[1]/10)
  test <- dat[samp,]
  train <- dat[-samp,]
  lm1 <- lm(wblot ~ 1+ poly(dose1,2) + poly(dose2,2), data = train)
  p_lm1 <- predict(lm1, test)
  R1 <- rbind(R1, RMSE(p_lm1, test$wblot))
}
```
Checking the basic assumptions of normality for the simple linear model, we can clearly see problems in the model. Comparing its prediction accuracy to the true dataset, we obtain `r quantile(p_lm1)`, which has a similar distribution mean. However, the tails of the predicted test dataset are wider than the true test dataset, which suggests that this model can be improved. Again, using the test data, the predicted response's Root Mean Squared Error (RMSE) is `r mean(R1)`.

#Proposed Model from Write-up 1
```{r}
fm1 <- lmer(wblot ~ 1 + (proto|lab) + body + poly(dose1,2) + poly(dose2,2), train)
summary(fm1)
```

```{r echo = F, warnings = F, cache = T}
R2 <- NULL
for(i in 1: 100){
  samp <- sample(dim(dat)[1], dim(dat)[1]/10)
  test <- dat[samp,]
  train <- dat[-samp,]
  fm1 <- lmer(wblot ~ 1 + (proto|lab) + body + poly(dose1,2) + poly(dose2,2), train)
  p_fm1 <- predict(fm1, test)
  R2 <- rbind(R2, RMSE(p_fm1, test$wblot))
}
ggplot(data = test, aes(p_fm1, wblot)) + geom_point(aes(colour = lab)) + geom_smooth() + geom_line(aes(colour=lab), linetype=5)
```
Based on our intuitive assumptions from Case Study 1, above is our proposed model from write-up 1. The plot demonstrates how well our proposed model's prediction of the test data fits the true test data--a linear trend indicates perfect prediction. Overall, the predictive power of our intuitive model seems to work pretty well. The distribution of our proposed model more closely follows that of the true dataset compared to the Simple Linear model, since the RMSE (`r mean(R2)`) is lower by `r R1-R2` in comparison to the baseline model. However, we were informed by a more experienced Statistician (our TA) about the necessity to model the data with a minimum equation of:

```{r}
fm2 <- lmer(wblot ~ 1 + (proto|lab) + body + poly(dose1,2) + poly(dose2,2), dat)
summary(fm2)
p_fm2 <- predict(fm2, dat)
ggplot(data = dat, aes(p_fm2, wblot)) + geom_smooth() + geom_point(aes(colour = lab), alpha = 0.3) 

```

However, for each dose, the response trend varies per lab.
```{r}
mean_dat1 <- dat %>% group_by(lab, dose1) %>% summarise(wblot = mean(wblot))
ggplot(data = mean_dat1, aes(x = dose1, y = wblot, color = lab)) + geom_line()
mean_dat2 <- dat %>% group_by(lab, dose2) %>% summarise(wblot = mean(wblot))
ggplot(data = mean_dat2, aes(x = dose2, y = wblot, color = lab)) + geom_line()

```

#minimum model proposed in class monday
Due to the high variance in the effect of dose between labs, the minimum model was altered to include dose1 and dose2 for each lab.
```{r}
#dose response curve
minmod <- lmer(wblot ~ (1 + proto + dose1 + dose2| lab), dat) #minimum model
summary(minmod)
plot(minmod)
p_minmod <- predict(minmod, test)
ggplot(data = dat, aes(p_minmod, wblot)) + geom_smooth() + geom_point(aes(colour = lab), alpha = 0.3) #+ geom_line(aes(colour=lab), linetype=5)

```

#adding characters from proposed model to monday model
```{r}
medmod <- lmer(wblot ~ (1 + poly(dose1,2) + poly(dose2,2) |lab)+poly(dose1,2)+poly(dose2,2)+poly(body,2)+(proto*lab), dat) #med model
summary(medmod)
plot(medmod)
p_medmod <- predict(medmod, dat)
ggplot(data = dat, aes(p_medmod, wblot)) + geom_point(aes(colour = lab)) + geom_smooth() #+ geom_line(aes(colour=lab), linetype=5)

par(mfrow = c(2,2))
test_p <- ggplot(data = test, aes(x = wblot)) + geom_histogram() + lims(x = c(0,4)) + theme_bw()
min_p <- ggplot(test,aes(p_minmod)) + geom_histogram() + lims(x = c(0,4)) + theme_bw()
med_p <- ggplot(test,aes(p_medmod)) + geom_histogram() + lims(x = c(0,4)) + theme_bw()
multiplot(test_p, min_p, med_p, cols = 2)
```
After exploring and comparing multiple models, our final model is $$y_{ij} = \mu_i + \beta_{i,dose1}\cdot dose1_{ij}^2 + \beta_{i,dose2}\cdot dose2_{ij}^2 + \gamma_{dose1}\cdot dose1_{ij}^2 + \gamma_{dose2}\cdot dose2_{ij}^2 + \gamma_{body}\cdot body_{ij}^2 + \gamma_{inter}\cdot proto_{ij}\cdot lab_{ij} +\epsilon_{ij}$$ where $\epsilon_{ij} \sim N(0,\nu^2)$ and $\mu_i \sim N(\mu, \sigma^2)$$.

We noticed that adding dose1 and dose2 as both fixed and random effects better fit the data. The fixed effect captures the population effects of dose1 and dose2 across all labs and random effect captures the variation in the effects of dose1 and dose2 between labs. Similarly, we also assumed that there were variations between protocol and lab, so we added an interaction term between protocol and lab as a fixed effect and as a random effect. The fixed effect captures the population differences between each protocol and lab, and the random effect captures the lab-specific variation between protocol and lab. We decided to transform body weight, dose1, and dose2 to a polynomial with a degree of 2 because the scatterplot indicated a nonlinear trend between body weight and the response, the weighted blot. 

Conclusion
From this final model, we can conclude the three major influences are:
1. Body weight, decreasing concave up effect
2. Dose 1, increasing concave down effect
3. Dose 2, decreasing concave up effect

Contributions
Sonia Xu - goodness-of-fit for every model (RMSE, test/training), wrote case study 2, explored models
InHee Ho - explored various models
Ian Hua - explored various models